{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 12:37:29.861200: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738240650.018094   19751 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738240650.057306   19751 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10000, 28, 28), (10000,)) ((10000, 28, 28), (10000,))\n",
      "((10000, 10), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = (X_train[:10000], y_train[:10000]), (X_test[:10000], y_test[:10000])\n",
    "\n",
    "print((X_train.shape, y_train.shape), (X_test.shape, y_test.shape))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "print((y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28) (10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "X_train, X_test = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]), X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2])\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nea.ml.nn import Module, Conv2D, Dense, ReLU, Reshape, SGD, MSE, Softmax\n",
    "from nea.ml.autograd import Tensor\n",
    "\n",
    "class MNISTER(Module):\n",
    "    def __init__(self):\n",
    "        self.conv2d_1 = Conv2D(X_train.shape[1:], 3, 5)\n",
    "        self.relu_1 = ReLU()\n",
    "        self.conv2d_2 = Conv2D((5, 26, 26), 3, 1)\n",
    "        self.relu_2 = ReLU()\n",
    "        self.reshape_1 = Reshape((576, ))\n",
    "        self.dense_1 = Dense(576, 256)\n",
    "        self.relu_3 = ReLU()\n",
    "        self.dense_2 = Dense(256, 10)\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    \n",
    "    def forward(self, x_sample: Tensor) -> Tensor:\n",
    "        out = self.conv2d_1(x_sample)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.conv2d_2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.reshape_1(out)\n",
    "        out = self.dense_1(out)\n",
    "        out = self.relu_3(out)\n",
    "        out = self.dense_2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "    def __call__(self, x_sample: Tensor) -> Tensor:\n",
    "        return self.forward(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------EPOCH: 0------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "<code object forward at 0x1c83f0e0, file \"/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/tensor.py\", line 972> != <code object cpu_forward_convolve2d at 0x7f92541a8f50, file \"/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/convolve_funcs.py\", line 6>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:592\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._get_func_code_info\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (6, '/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/convolve_funcs.py', <code object cpu_forward_convolve2d at 0x7f92541a8f50, file \"/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/convolve_funcs.py\", line 6>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_idx, end_idx):\n\u001b[0;32m---> 19\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_func(pred, y_train[sample])\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m, in \u001b[0;36mMNISTER.__call__\u001b[0;34m(self, x_sample)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_sample: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mMNISTER.forward\u001b[0;34m(self, x_sample)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_sample: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 18\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu_1(out)\n\u001b[1;32m     20\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2d_2(out)\n",
      "File \u001b[0;32m/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/nn/layers.py:40\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensorable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/nn/layers.py:206\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding:\n\u001b[1;32m    205\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpad2D(padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_value)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbiases\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/tensor.py:270\u001b[0m, in \u001b[0;36mTensor.convolve2d\u001b[0;34m(self, k, b)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"2D convolutional layer of the tensor\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    Tensor:\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m conv_op \u001b[38;5;241m=\u001b[39m Convolve2D()\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconv_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/tensor.py:991\u001b[0m, in \u001b[0;36mConvolve2D.forward\u001b[0;34m(self, x, k, b)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b:\n\u001b[1;32m    989\u001b[0m     new_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m--> 991\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mcpu_forward_convolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_kernels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m y \u001b[38;5;241m=\u001b[39m Tensor(new_data, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_grad_enabled():\n",
      "File \u001b[0;32m<stringsource>:69\u001b[0m, in \u001b[0;36mcfunc.to_py.__Pyx_CFunc_893235__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_18instruction_offset.wrap\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1702\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._start_method_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:599\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._get_func_code_info\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: <code object forward at 0x1c83f0e0, file \"/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/tensor.py\", line 972> != <code object cpu_forward_convolve2d at 0x7f92541a8f50, file \"/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/convolve_funcs.py\", line 6>"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "model = MNISTER()\n",
    "optim = SGD(model.params)\n",
    "loss_func = MSE()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"---------EPOCH: {epoch}------------\")\n",
    "\n",
    "    for start_idx in tqdm(range(0, X_train.shape[0], batch_size)):\n",
    "        end_idx = min(X_train.shape[0], start_idx + batch_size)\n",
    "        \n",
    "        loss = 0\n",
    "        for sample in range(start_idx, end_idx):\n",
    "            pred = model(X_train[sample])\n",
    "            loss += loss_func(pred, y_train[sample])\n",
    "\n",
    "    \n",
    "    loss = loss.mean()\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "print(\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nea-vDgE-14l-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
