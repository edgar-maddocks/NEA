{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nea.ml.nn import (\n",
    "    Module,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    ReLU,\n",
    "    Tanh,\n",
    "    Reshape,\n",
    "    MinMaxNormalization,\n",
    "    SGD,\n",
    "    MSE,\n",
    "    Softmax,\n",
    "    Sigmoid,\n",
    "    CrossEntropy,\n",
    ")\n",
    "from nea.ml.autograd import Tensor, no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28)\n",
      "((60000, 10), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "\"\"\"train_filter = np.where((y_train == 0) | (y_train == 4))\n",
    "test_filter = np.where((y_test == 0) | (y_test == 4))\n",
    "\n",
    "X_train, y_train = X_train[train_filter], y_train[train_filter]\n",
    "X_test, y_test = X_test[test_filter], y_test[test_filter]\"\"\"\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "X_train, X_test = (\n",
    "    X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]),\n",
    "    X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]),\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print((y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTER(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = Conv2D(X_train.shape[1:], 9, 5)\n",
    "        self.sigmoid_1 = Sigmoid()\n",
    "        self.reshape_1 = Reshape((1, 2000))\n",
    "        self.dense_1 = Dense(2000, 784)\n",
    "        self.sigmoid_2 = Sigmoid()\n",
    "        self.dense_2 = Dense(784, 256)\n",
    "        self.sigmoid_3 = Sigmoid()\n",
    "        self.dense_3 = Dense(256, 5)\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def forward(self, x_sample: Tensor) -> Tensor:\n",
    "        out = self.conv2d_1(x_sample)\n",
    "        out = self.sigmoid_1(out)\n",
    "        out = self.reshape_1(out)\n",
    "        out = self.dense_1(out)\n",
    "        out = self.sigmoid_2(out)\n",
    "        out = self.dense_2(out)\n",
    "        out = self.sigmoid_3(out)\n",
    "        out = self.dense_3(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "    def __call__(self, x_sample: Tensor) -> Tensor:\n",
    "        return self.forward(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTER()\n",
    "optim = SGD(model.params, lr=0.01, regulization=0)\n",
    "loss_func = CrossEntropy()\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 0. True: 7\n",
      "Pred: 0. True: 2\n",
      "Pred: 0. True: 1\n",
      "Pred: 0. True: 0\n",
      "Pred: 0. True: 4\n"
     ]
    }
   ],
   "source": [
    "for x in range(0, 5):\n",
    "    pred = model(X_test[x])\n",
    "    print(f\"Pred: {np.argmax(pred.data)}. True: {np.argmax(y_test[x])}\")\n",
    "\n",
    "trues = np.argmax(y_test, axis=-1)\n",
    "\n",
    "preds = []\n",
    "for x in range(0, X_test.shape[0]):\n",
    "    with no_grad():\n",
    "        pred = model(X_test[x])\n",
    "        preds.append(np.argmax(pred.data))\n",
    "\n",
    "accuracy = np.array((preds == trues)).astype(int)\n",
    "\n",
    "pct_score = accuracy.mean() * 100\n",
    "\n",
    "print(f\"Dataset Percentage Accuracy: {pct_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------EPOCH: 1------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 238/11765 [00:13<11:00, 17.44it/s]\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "CPUDispatcher(<function cpu_forward_convolve2d at 0x7f79766cb880>) returned a result with an exception set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nea-vDgE-14l-py3.12/lib/python3.12/site-packages/numba/core/serialize.py:30\u001b[0m, in \u001b[0;36m_numba_unpickle\u001b[0;34m(address, bytedata, hashed)\u001b[0m\n\u001b[1;32m     27\u001b[0m _unpickled_memo \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_numba_unpickle\u001b[39m(address, bytedata, hashed):\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Used by `numba_unpickle` from _helperlib.c\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m        unpickled object\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m Tensor(\u001b[38;5;241m0\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, X_train[:\u001b[38;5;241m20000\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])):\n\u001b[0;32m----> 6\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_func(pred\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m)), Tensor(y_train[sample]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m      8\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m, in \u001b[0;36mMNISTER.__call__\u001b[0;34m(self, x_sample)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_sample: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mMNISTER.forward\u001b[0;34m(self, x_sample)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_sample: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 15\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid_1(out)\n\u001b[1;32m     17\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape_1(out)\n",
      "File \u001b[0;32m/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/nn/layers.py:40\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensorable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/nn/layers.py:207\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding:\n\u001b[1;32m    206\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpad2D(padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_value)\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbiases\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/tensor.py:274\u001b[0m, in \u001b[0;36mTensor.convolve2d\u001b[0;34m(self, k, b)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"2D convolutional layer of the tensor\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Tensor:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m conv_op \u001b[38;5;241m=\u001b[39m Convolve2D()\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconv_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/edgar/OneDrive/Documents/GitHub/NEA/nea/ml/autograd/tensor.py:997\u001b[0m, in \u001b[0;36mConvolve2D.forward\u001b[0;34m(self, x, k, b)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b:\n\u001b[1;32m    995\u001b[0m     new_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m--> 997\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mcpu_forward_convolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_kernels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m y \u001b[38;5;241m=\u001b[39m Tensor(new_data, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_grad_enabled():\n",
      "\u001b[0;31mSystemError\u001b[0m: CPUDispatcher(<function cpu_forward_convolve2d at 0x7f79766cb880>) returned a result with an exception set"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"---------EPOCH: {epoch + 1}------------\")\n",
    "\n",
    "    loss = Tensor(0, requires_grad=True)\n",
    "    for sample in tqdm(range(0, X_train[:20000].shape[0])):\n",
    "        pred = model(X_train[sample])\n",
    "        loss = loss_func(pred.reshape((5, 1)), Tensor(y_train[sample].reshape(5, 1)))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    with no_grad():\n",
    "        loss = 0\n",
    "        for sample in tqdm(range(0, X_test.shape[0])):\n",
    "            pred = model(X_test[sample])\n",
    "            loss += loss_func(\n",
    "                pred.reshape((5, 1)), Tensor(y_test[sample].reshape(5, 1))\n",
    "            )\n",
    "\n",
    "        loss /= X_test.shape[0]\n",
    "\n",
    "        print(f\"TEST LOSS: {loss}\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    for x in range(0, 5):\n",
    "        pred = model(X_test[x])\n",
    "        print(f\"Pred: {np.argmax(pred.data)}. True: {np.argmax(y_test[x])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1962/1962 [00:06<00:00, 316.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.34964322120285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trues = np.argmax(y_test, axis=-1)\n",
    "\n",
    "preds = []\n",
    "for x in tqdm(range(0, X_test.shape[0])):\n",
    "    with no_grad():\n",
    "        pred = model(X_test[x])\n",
    "        preds.append(np.argmax(pred.data))\n",
    "\n",
    "accuracy = np.array((preds == trues)).astype(int)\n",
    "\n",
    "pct_score = accuracy.mean() * 100\n",
    "\n",
    "print(pct_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nea-vDgE-14l-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
