{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 16:05:14.857004: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-20 16:05:14.907191: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-20 16:05:14.961974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740067515.043499   27339 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740067515.071613   27339 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-20 16:05:15.227856: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nea.ml.nn import (\n",
    "    Module,\n",
    "    ModuleList,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    ReLU,\n",
    "    Tanh,\n",
    "    Reshape,\n",
    "    MinMaxNormalization,\n",
    "    SGD,\n",
    "    MSE,\n",
    "    AlphaLoss,\n",
    "    Softmax,\n",
    "    Sigmoid,\n",
    "    CrossEntropy,\n",
    ")\n",
    "from nea.ml.autograd import Tensor, no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (10000, 1, 28, 28)\n",
      "((60000, 10), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "\"\"\"train_filter = np.where((y_train == 0) | (y_train == 4))\n",
    "test_filter = np.where((y_test == 0) | (y_test == 4))\n",
    "\n",
    "X_train, y_train = X_train[train_filter], y_train[train_filter]\n",
    "X_test, y_test = X_test[test_filter], y_test[test_filter]\"\"\"\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "X_train, X_test = (\n",
    "    X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2]),\n",
    "    X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2]),\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print((y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTER(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = Conv2D(X_train.shape[1:], 9, 5)\n",
    "        self.sigmoid_1 = Sigmoid()\n",
    "        self.reshape_1 = Reshape((1, 2000))\n",
    "        self.dense_1 = Dense(2000, 784)\n",
    "        self.sigmoid_2 = Sigmoid()\n",
    "        self.dense_2 = Dense(784, 256)\n",
    "        self.sigmoid_3 = Sigmoid()\n",
    "        self.dense_3 = Dense(256, 10)\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def forward(self, x_sample: Tensor) -> Tensor:\n",
    "        out = self.conv2d_1(x_sample)\n",
    "        out = self.sigmoid_1(out)\n",
    "        out = self.reshape_1(out)\n",
    "        out = self.dense_1(out)\n",
    "        out = self.sigmoid_2(out)\n",
    "        out = self.dense_2(out)\n",
    "        out = self.sigmoid_3(out)\n",
    "        out = self.dense_3(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "    def __call__(self, x_sample: Tensor) -> Tensor:\n",
    "        return self.forward(x_sample)\n",
    "    \n",
    "    def save(self, file_path: str) -> None:\n",
    "        with open(file_path, \"wb\") as fh:\n",
    "            pickle.dump(self, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTER()\n",
    "optim = SGD(model.params, lr=0.01, regulization=0)\n",
    "loss_func = CrossEntropy()\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 0. True: 7\n",
      "Pred: 7. True: 2\n",
      "Pred: 7. True: 1\n",
      "Pred: 7. True: 0\n",
      "Pred: 0. True: 4\n",
      "Dataset Percentage Accuracy: 8.33\n"
     ]
    }
   ],
   "source": [
    "for x in range(0, 5):\n",
    "    pred = model(X_test[x])\n",
    "    print(f\"Pred: {np.argmax(pred.data)}. True: {np.argmax(y_test[x])}\")\n",
    "\n",
    "trues = np.argmax(y_test, axis=-1)\n",
    "\n",
    "preds = []\n",
    "for x in range(0, X_test.shape[0]):\n",
    "    with no_grad():\n",
    "        pred = model(X_test[x])\n",
    "        preds.append(np.argmax(pred.data))\n",
    "\n",
    "accuracy = np.array((preds == trues)).astype(int)\n",
    "\n",
    "pct_score = accuracy.mean() * 100\n",
    "\n",
    "print(f\"Dataset Percentage Accuracy: {pct_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mnister.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 0. True: 7\n",
      "Pred: 7. True: 2\n",
      "Pred: 7. True: 1\n",
      "Pred: 7. True: 0\n",
      "Pred: 0. True: 4\n"
     ]
    }
   ],
   "source": [
    "loaded_model = MNISTER.load(\"mnister.pkl\")\n",
    "\n",
    "for x in range(0, 5):\n",
    "    pred = loaded_model(X_test[x])\n",
    "    print(f\"Pred: {np.argmax(pred.data)}. True: {np.argmax(y_test[x])}\")\n",
    "\n",
    "trues = np.argmax(y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------EPOCH: 1------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [37:41<00:00, 26.53it/s]  \n",
      "100%|██████████| 10000/10000 [01:23<00:00, 119.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LOSS: Tensor([0.50855749], shape = (1,)) - Accuracy: 84.48\n",
      "---------EPOCH: 2------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [33:14<00:00, 30.08it/s]  \n",
      "100%|██████████| 10000/10000 [00:49<00:00, 201.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LOSS: Tensor([0.42650206], shape = (1,)) - Accuracy: 87.87\n",
      "---------EPOCH: 3------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [34:55<00:00, 28.63it/s]  \n",
      "100%|██████████| 10000/10000 [00:54<00:00, 183.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LOSS: Tensor([0.41278366], shape = (1,)) - Accuracy: 87.99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"---------EPOCH: {epoch + 1}------------\")\n",
    "\n",
    "    loss = Tensor(0, requires_grad=True)\n",
    "    for sample in tqdm(range(0, X_train.shape[0])):\n",
    "        pred = model(X_train[sample])\n",
    "        loss = loss_func(pred.reshape((10, 1)), Tensor(y_train[sample].reshape(10, 1)))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    with no_grad():\n",
    "        \n",
    "        loss = 0\n",
    "        preds = []\n",
    "        trues = np.argmax(y_test, axis=-1)\n",
    "\n",
    "        for sample in tqdm(range(0, X_test.shape[0])):\n",
    "            pred = model(X_test[sample])\n",
    "            preds.append(np.argmax(pred.data))\n",
    "            loss += loss_func(\n",
    "                pred.reshape((10, 1)), Tensor(y_test[sample].reshape(10, 1))\n",
    "            )\n",
    "    \n",
    "        accuracy = np.array((preds == trues)).astype(int)\n",
    "\n",
    "        pct_score = accuracy.mean() * 100\n",
    "\n",
    "        loss /= X_test.shape[0]\n",
    "\n",
    "        print(f\"TEST LOSS: {loss} - Accuracy: {pct_score}\")\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nea-78Vhzb2n-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
